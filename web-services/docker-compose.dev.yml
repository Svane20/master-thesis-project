services:
  resnet-onnx:
    build:
      context: .
      dockerfile: resnet/onnx/Dockerfile
      args:
        USE_GPU: "true"
        BASE_IMAGE: "nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04"
#        USE_GPU: "false"
#        BASE_IMAGE: "python:3.10-slim"
    container_name: resnet-onnx
    environment:
      - PROMETHEUS_METRICS_ENABLED=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - MAX_BATCH_SIZE=8
      - USE_GPU=true
#      - USE_GPU=false # Set to false if using CPU
    gpus: all # Disable this line if using CPU
    restart: always
    depends_on:
      - prometheus

  resnet-torchscript:
    build:
      context: .
      dockerfile: resnet/torchscript/Dockerfile
      args:
        USE_GPU: "true"
        BASE_IMAGE: "nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04"
    #        USE_GPU: "false"
    #        BASE_IMAGE: "python:3.10-slim"
    container_name: resnet-torchscript
    environment:
      - PROMETHEUS_METRICS_ENABLED=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - MAX_BATCH_SIZE=8
      - USE_GPU=true
    #      - USE_GPU=false # Set to false if using CPU
    gpus: all # Disable this line if using CPU
    restart: always
    depends_on:
      - prometheus

  resnet-pytorch:
    build:
      context: .
      dockerfile: resnet/pytorch/Dockerfile
      args:
        USE_GPU: "true"
        BASE_IMAGE: "nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04"
    #        USE_GPU: "false"
    #        BASE_IMAGE: "python:3.10-slim"
    container_name: resnet-pytorch
    environment:
      - PROMETHEUS_METRICS_ENABLED=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - MAX_BATCH_SIZE=8
      - USE_GPU=true
    #      - USE_GPU=false # Set to false if using CPU
    gpus: all # Disable this line if using CPU
    restart: always
    depends_on:
      - prometheus

  swin-onnx:
    build:
      context: .
      dockerfile: swin/onnx/Dockerfile
      args:
        USE_GPU: "true"
        BASE_IMAGE: "nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04"
    #        USE_GPU: "false"
    #        BASE_IMAGE: "python:3.10-slim"
    container_name: swin-onnx
    environment:
      - PROMETHEUS_METRICS_ENABLED=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - MAX_BATCH_SIZE=8
      - USE_GPU=true
    #      - USE_GPU=false # Set to false if using CPU
    gpus: all # Disable this line if using CPU
    restart: always
    depends_on:
      - prometheus

  swin-torchscript:
    build:
      context: .
      dockerfile: swin/torchscript/Dockerfile
      args:
        USE_GPU: "true"
        BASE_IMAGE: "nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04"
    #        USE_GPU: "false"
    #        BASE_IMAGE: "python:3.10-slim"
    container_name: swin-torchscript
    environment:
      - PROMETHEUS_METRICS_ENABLED=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - MAX_BATCH_SIZE=8
      - USE_GPU=true
    #      - USE_GPU=false # Set to false if using CPU
    gpus: all # Disable this line if using CPU
    restart: always
    depends_on:
      - prometheus

  swin-pytorch:
    build:
      context: .
      dockerfile: swin/pytorch/Dockerfile
      args:
        USE_GPU: "true"
        BASE_IMAGE: "nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04"
    #        USE_GPU: "false"
    #        BASE_IMAGE: "python:3.10-slim"
    container_name: swin-pytorch
    environment:
      - PROMETHEUS_METRICS_ENABLED=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - MAX_BATCH_SIZE=8
      - USE_GPU=true
    #      - USE_GPU=false # Set to false if using CPU
    gpus: all # Disable this line if using CPU
    restart: always
    depends_on:
      - prometheus

  dpt-onnx:
    build:
      context: .
      dockerfile: dpt/onnx/Dockerfile
      args:
        USE_GPU: "true"
        BASE_IMAGE: "nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04"
    #        USE_GPU: "false"
    #        BASE_IMAGE: "python:3.10-slim"
    container_name: dpt-onnx
    environment:
      - PROMETHEUS_METRICS_ENABLED=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - MAX_BATCH_SIZE=8
      - USE_GPU=true
    #      - USE_GPU=false # Set to false if using CPU
    gpus: all # Disable this line if using CPU
    restart: always
    depends_on:
      - prometheus

  dpt-torchscript:
    build:
      context: .
      dockerfile: dpt/torchscript/Dockerfile
      args:
        USE_GPU: "true"
        BASE_IMAGE: "nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04"
    #        USE_GPU: "false"
    #        BASE_IMAGE: "python:3.10-slim"
    container_name: dpt-torchscript
    environment:
      - PROMETHEUS_METRICS_ENABLED=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - MAX_BATCH_SIZE=8
      - USE_GPU=true
    #      - USE_GPU=false # Set to false if using CPU
    gpus: all # Disable this line if using CPU
    restart: always
    depends_on:
      - prometheus

  dpt-pytorch:
    build:
      context: .
      dockerfile: dpt/pytorch/Dockerfile
      args:
        USE_GPU: "true"
        BASE_IMAGE: "nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04"
    #        USE_GPU: "false"
    #        BASE_IMAGE: "python:3.10-slim"
    container_name: dpt-pytorch
    environment:
      - PROMETHEUS_METRICS_ENABLED=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - MAX_BATCH_SIZE=8
      - USE_GPU=true
    #      - USE_GPU=false # Set to false if using CPU
    gpus: all # Disable this line if using CPU
    restart: always
    depends_on:
      - prometheus

  nginx:
    image: nginx:latest
    container_name: nginx
    ports:
      - "80:80"
    volumes:
      - ./configs/nginx/nginx.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - resnet-onnx
      - resnet-torchscript
      - resnet-pytorch
      - swin-onnx
      - swin-torchscript
      - swin-pytorch
      - dpt-onnx
      - dpt-torchscript
      - dpt-pytorch


  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./configs/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    restart: always

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus
    restart: always
    volumes:
      - grafana_data:/var/lib/grafana
      - ./configs/grafana/provisioning/:/etc/grafana/provisioning/
      - ./configs/grafana/dashboards/:/var/lib/grafana/dashboards/

volumes:
  prometheus_data:
  grafana_data: